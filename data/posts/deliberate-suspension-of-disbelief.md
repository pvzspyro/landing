In May 1977 in the depths of a PDP-10, at this time state-of-the-art computer residing in the MIT basement, *Zork* program was started for the very first time. Hobbyist project of Tim Anderson, Marc Blank, Bruce Daniels and Dave Lebling.

In DnD, a role-playing game, group of people gather around table to listen and play out fantasy adventures told and guided by the skilled Dungeon Master. DM paints a picture for adventurers as they progress throughout the imagined world, both using nothing but words and occasional props to experience breathtaking adventures. Zork was a first where that human role of Dungeon Master was replaced by a machine. It painted you a picture and accepted text commands to progress you through, while you wer solving puzzles and living experiences as you went - you and a machine on an adventure together.

Back in the day a PDP-10 computer was available for not only our Zork creators but also other researchers without much trouble via ARPANET - very crude version of what become World Wide Web as we know it today. They found Zork and it quickly gained traction, respect of the peers and loyal fanbase by the word-of-mouth. That enthusiasm pushed it's creators to develop it further with new environments, adventures, systems and objects till 1981 when it's codebase size crossed magical barrier of 1MB - maximum then readable by PDP-10 amount of memory.

Zork's creation coincided with popularization of the first personal computers such as Apple 2, becoming over the years a bestseller with 360 000 copies sold worldwide until it was bought by Activision in 1986 (yeah, Activision is that old).

Zork was revolutionary on multiple levels, being one of the prime examples how rich and engaging world computer can simulate, or rather, how closely a computer can simulate a human on the level of experiences and emotions it triggers within us while interacting with. Zork's world, however engaging, was 100% handcrafted. Digital diorama written down line by line where each imaginary rock, tree or puzzle was deliberately placed by it's creators and each cynic response written down beforehand. It outcomes were deterministic and not branched - finish it one and all replays will just repeat the experience.

Success like that doesn't go unnoticed - their inevitable outcome is a flow of cash from excited investors that propels following projects and their technology exponentially into more or less successful directions. One of it was embedding alghoritmic systems into the digital experiences such as procedural world generation, collisions, pathfinding or flocking. Even though the outcome of multiple alghrotims interacting with each other is still deterministic, the amount of possible outcomes goes to infinity. That substantially improved the experience as well as replaiability of created titles. Some, such as Dwarf Fortress, taking it to the near extremes where you manage and develop your colony of dwarfs and each object you come into interaction with has history more rich than most of the post ZSSR countries. All of that in ASCII char interface.

Both Zork and Dwarf Fortess excelled in one area while being pretty imperfect in other but those were becoming less and less noticeable as technology, compute and hardware grew to the point of reaching titles like Mass Effect or The Witcher where when stars align, you are tired enough or don't care enough and the game is good enough, for a glimpse, a brief moment in time you can immerse yourself in the adventure to the point where it feels real. Excitement, curiosity, sadness, all the emotions you feel deep within you making it an experience worthy of reality. Mine was Sea of Thieves somewhere during Covid. A moment shared with friends on the deck of a ship. Shanties, rum and the vastness of the sea. A perfect sunset over an island on the horizon. Adventure filled with emotions. I knew in the moment it was just a game, a collection of alghoritms and approximations, but felt as real as anything else and one I fondly recall to this day. 

What I came to understand from it was that *the knowledge of inner working of it only adds to the excitement and mystery and awe.* Knowing how my adventure works didn't made it less enjoyable, maybe even more.

---

Being around various different applications of Machine Learning over the years I've lived with a conviction that it's an interesting concept, however no different than other alghoritms developed over the times. Code is force multiplier. Using it for things like detecting cats from dogs was just force multiplier to problems too complex to be bound by declarative alghoritms. Problems where explicit rules for solving it were either unknown or infeasible so we derive patterns from vast amount of data instead and the output is just good enough to make a difference.

I watched this area of research grow alongside me from those simple solutions, through BERT, GPT-2, 3 to what it is today with an unwaivered conviction that all of those great scientific breakthroughs and technological advancements made along the way won't matter that much and while useful, it's still only a statistical pattern-matching machine, just bigger and harder to comprehend.

https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web

I loved this piece and subscribed to the metaphore of it being nothing else but a blurred image of the web. I referenced it a lot to people asking me about AI. While AI being glorified pattern-matching machine still holds true today, I understand now that it's impact on our lives will be vastly greater than I have ever dreamed of. 

Starting with Zork, over time we manufactured an adventure to the point where at times you cannot tell it from the "real" thing. Heart rate. Adrenaline. Excitement. Memories. Starting with GPT we will over time manufacture artificial intelligence to the point where we won't be able to tell it from "our" natural intelligence. Whether we achieve actual AGI may be irrelevant, the line will fade day by day to the point where we either won't care or won't notice it's here. I would even say it already faded in areas where reward functions guided the current SOTA models to excel.

---

What was eluding me is the fact that my smart white collar job is largely based on my wetware matching patterns on a daily basis already. No reason for artificial pattern-matching machine to do worse job of it. And while brain and it's inner workings is still largely a mystery, there is no reason to belief that, at it's core it doesn't follow some primitive physics principles that we can recreate. So far in the history of humanity there weren't a problems that we couldn't get to a bottom of using physics, just problems we didn't solve yet.

Most prominent argument for current LLM being incapable of reaching AGI is the fact that they operate within bounds of knowledge derived from already discovered and found solutions by the collective of the humankind, which makes it's work not original, but rather derivative from what already produced, seen and experienced. Alright, when is the last time you had the original thought? What I am doing, writing, thinking of is already a derivative of what I've seen and experienced over they years and even if I stumble upon idea that feels original to me quick lookup grounds me back in the reality.

*the knowledge of inner working of it only adds to the excitement and mystery and awe.* - Let's take that part of this essay about knowing how things work makes it even better experience? Yeah, Feynmann reached this conclusion before I was even born.

_'I have a friend who's an artist and he's some times taken a view which I don't agree with very well. He'll hold up a flower and say, "look how beautiful it is," and I'll agree, I think. And he says, "you see, I as an artist can see how beautiful this is, but you as a scientist, oh, take this all apart and it becomes a dull thing." And I think he's kind of nutty. First of all, the beauty that he sees is available to other people and to me, too, I believe, although I might not be quite as refined aesthetically as he is. But I can appreciate the beauty of a flower. At the same time, I see much more about the flower that he sees. I could imagine the cells in there, the complicated actions inside which also have a beauty. I mean, it's not just beauty at this dimension of one centimeter: there is also beauty at a smaller dimension, the inner structure... also the processes. The fact that the colors in the flower are evolved in order to attract insects to pollinate it is interesting - it means that insects can see the color. It adds a question - does this aesthetic sense also exist in the lower forms that are... why is it aesthetic, all kinds of interesting questions which a science knowledge only adds to the excitement and mystery and the awe of a flower. It only adds. I don't understand how it subtracts.'_

On the scale of humankind there is not that many purely original thoughts as one would think, everything is derived from first principles. I don't even know if over the course of my life I had at least one of such kind. I am closer to a pattern matching machine that I would like to admit, distilling interpolated thoughts into derivated ideas and beliefs.

I love that intelligence is finally so sought after. Smart and extremely sharp in respective field is the new sexy and I could not be happier for those people. But we, as a majority, me included, are not one of them. That magical 0.1% of population blessed with what could be considered an original thought is now worth x1000 than what I will if we compare for raw analytical capabilities. Being in the middle of bell curve sucks, not dumb enough to not care and not smart enough to stay relevant in the long run. I will adapt and use AI in my daily work. At some point I will work with it hand by hand. Maybe a decade or two down the road AI will use me in it's daily work. Until I am no longer needed in the cycle.

 It was eating me from inside for a while - where working every day to replace myself will lead me. Without a comfortable white collar cushion. Whether the endgame is one of those rare utopian scenarios or what I am more inclined to believe, dystopian one. I don't anymore, my pattern-matching machine implemented in goo found a way out. I choose to live in deliberate suspension of disbelief to wake up in the morning and not hang myself. 
 
When the day comes - and it will come - I hope to be okay with myself retreating into the safety net of family and familiar faces, becoming just another irrelevant data point in the crowd. And yet, I remain deeply, genuinely glad that I live in an era where I can witness the greatest civilizational progress, the defining turning point of our age, unfolding in real time - changes so vast and irreversible that simply being here to see them feels extraordinary, even if their final outcome isnâ€™t favourable for me.

Deliberate suspension of disbelief while in awe of technological advancements is the only logical way forward.